{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef0b158b0588392",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:02.801451Z",
     "start_time": "2024-08-12T00:32:00.316826Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (5.1)\n",
      "fatal: destination path 'detectron2' already exists and is not an empty directory.\n",
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
      "Requirement already satisfied: Pillow>=7.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: matplotlib in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (2.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (2.4.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (0.1.8)\n",
      "Requirement already satisfied: tabulate in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: tensorboard in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (2.17.1)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: black in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (24.8.0)\n",
      "Requirement already satisfied: packaging in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (4.54.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: PyYAML in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from yacs>=0.1.8) (5.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (1.66.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (5.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from tensorboard) (3.0.4)\n",
      "Requirement already satisfied: portalocker in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from iopath<0.1.10,>=0.1.7) (2.10.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from black) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from black) (4.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# # Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0411de6a0ad138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:07.268702Z",
     "start_time": "2024-08-12T00:32:07.124644Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n",
      "torch:  2.2 ; cuda:  2.2.2\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6462041cf4997a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:11.424884Z",
     "start_time": "2024-08-12T00:32:11.419802Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib data path: /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/matplotlib/mpl-data\n",
      "CONFIGDIR=/Users/muriellemardenli/.matplotlib\n",
      "interactive is False\n",
      "platform is darwin\n",
      "CACHEDIR=/Users/muriellemardenli/.matplotlib\n",
      "Using fontManager instance from /Users/muriellemardenli/.matplotlib/fontlist-v390.json\n"
     ]
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import os, json, random, cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d48db80f6643ba6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:12.975415Z",
     "start_time": "2024-08-12T00:32:12.970866Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " METADATA CATALOG\n",
      "['coco_2014_train', 'coco_2014_val', 'coco_2014_minival', 'coco_2014_valminusminival', 'coco_2017_train', 'coco_2017_val', 'coco_2017_test', 'coco_2017_test-dev', 'coco_2017_val_100', 'keypoints_coco_2014_train', 'keypoints_coco_2014_val', 'keypoints_coco_2014_minival', 'keypoints_coco_2014_valminusminival', 'keypoints_coco_2017_train', 'keypoints_coco_2017_val', 'keypoints_coco_2017_val_100', 'coco_2017_train_panoptic_separated', 'coco_2017_train_panoptic_stuffonly', 'coco_2017_train_panoptic', 'coco_2017_val_panoptic_separated', 'coco_2017_val_panoptic_stuffonly', 'coco_2017_val_panoptic', 'coco_2017_val_100_panoptic_separated', 'coco_2017_val_100_panoptic_stuffonly', 'coco_2017_val_100_panoptic', 'lvis_v1_train', 'lvis_v1_val', 'lvis_v1_test_dev', 'lvis_v1_test_challenge', 'lvis_v0.5_train', 'lvis_v0.5_val', 'lvis_v0.5_val_rand_100', 'lvis_v0.5_test', 'lvis_v0.5_train_cocofied', 'lvis_v0.5_val_cocofied', 'cityscapes_fine_instance_seg_train', 'cityscapes_fine_sem_seg_train', 'cityscapes_fine_instance_seg_val', 'cityscapes_fine_sem_seg_val', 'cityscapes_fine_instance_seg_test', 'cityscapes_fine_sem_seg_test', 'cityscapes_fine_panoptic_train', 'cityscapes_fine_panoptic_val', 'voc_2007_trainval', 'voc_2007_train', 'voc_2007_val', 'voc_2007_test', 'voc_2012_trainval', 'voc_2012_train', 'voc_2012_val', 'ade20k_sem_seg_train', 'ade20k_sem_seg_val', '../src/coco/annotations/json_annotation_val.json', '../src/coco/annotations/json_annotation_train.json', '../src/data-coco/annotations/json_annotation_train.json', '../src/data-coco/annotations/json_annotation_val.json']\n"
     ]
    }
   ],
   "source": [
    "# Register Dataset\n",
    "# Must be run everytime you train ONLY ONCE\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"../src/data-coco/annotations/json_annotation_train.json\", {}, \"../src/data-coco/annotations/json_annotation_train.json\", \"../src/data-coco/images/train\")\n",
    "register_coco_instances(\"../src/data-coco/annotations/json_annotation_val.json\", {},\"../src/data-coco/annotations/json_annotation_val.json\" , \"../src/data-coco/images/val\")\n",
    "print('\\n METADATA CATALOG')\n",
    "print(list(detectron2.data.MetadataCatalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f41885edc891aafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T01:02:04.434132Z",
     "start_time": "2024-08-12T00:32:14.923334Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/30 10:41:37 d2.engine.defaults]: \u001b[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/30 10:41:37 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from ../src/data-coco/annotations/json_annotation_train.json\n",
      "\u001b[32m[09/30 10:41:37 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 10 images left.\n",
      "\u001b[32m[09/30 10:41:37 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    axon    | 7996         |   myelin   | 4753         |\n",
      "|            |              |            |              |\n",
      "|   total    | 12749        |            |              |\u001b[0m\n",
      "\u001b[32m[09/30 10:41:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/30 10:41:37 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/30 10:41:37 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/30 10:41:37 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/30 10:41:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.39 MiB\n",
      "\u001b[32m[09/30 10:41:37 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[09/30 10:41:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...\n",
      "URL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl cached in /Users/muriellemardenli/.torch/iopath_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl\n",
      "[Checkpointer] Loading from /Users/muriellemardenli/.torch/iopath_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...\n",
      "Reading a file from 'Detectron2 Model Zoo'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mpixel_mean\u001b[0m\n",
      "  \u001b[35mpixel_std\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/30 10:41:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1711403213615/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/30 10:58:01 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 19  total_loss: 3.416  loss_cls: 1.97  loss_box_reg: 1.232    time: 47.3028  last_time: 48.3471  data_time: 0.4865  last_data_time: 0.0165   lr: 7.9337e-05  \n",
      "\u001b[32m[09/30 11:16:53 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 39  total_loss: 1.038  loss_cls: 0.3575  loss_box_reg: 0.6732    time: 46.9037  last_time: 39.5909  data_time: 0.0070  last_data_time: 0.0022   lr: 0.00016259  \n",
      "Saving checkpoint to ./output/model_final.pth\n",
      "\u001b[32m[09/30 11:34:34 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 59  total_loss: 0.8959  loss_cls: 0.2918  loss_box_reg: 0.6161    time: 46.6257  last_time: 38.9885  data_time: 0.0075  last_data_time: 0.0013   lr: 0.00024584  \n",
      "\u001b[32m[09/30 11:34:34 d2.engine.hooks]: \u001b[0mOverall training speed: 58 iterations in 0:45:04 (46.6257 s / it)\n",
      "\u001b[32m[09/30 11:34:34 d2.engine.hooks]: \u001b[0mTotal training time: 0:45:05 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"../src/data-coco/annotations/json_annotation_train.json\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 60    # number of epochs\n",
    "# 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cpu\"  # Force CPU usage\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae2bbdde6d41682b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T01:08:34.842564Z",
     "start_time": "2024-08-12T01:08:33.208372Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45269), started 10:35:19 ago. (Use '!kill 45269' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-44b3c1af4be4c176\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-44b3c1af4be4c176\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6d8978d3b1fe0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T01:11:33.216787Z",
     "start_time": "2024-08-12T01:11:32.382927Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/30 11:49:16 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n",
      "[Checkpointer] Loading from ./output/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8facc1245996c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T01:11:56.305582Z",
     "start_time": "2024-08-12T01:11:51.732606Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/30 11:49:18 d2.data.datasets.coco]: \u001b[0mLoaded 10 images in COCO format from ../src/data-coco/annotations/json_annotation_val.json\n",
      "\u001b[32m[09/30 11:49:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[09/30 11:49:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/30 11:49:18 d2.data.common]: \u001b[0mSerializing 10 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/30 11:49:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.39 MiB\n",
      "\u001b[32m[09/30 11:49:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 10 batches\n",
      "\u001b[32m[09/30 11:49:31 d2.evaluation.evaluator]: \u001b[0mInference done 1/10. Dataloading: 5.8781 s/iter. Inference: 7.2257 s/iter. Eval: 0.0005 s/iter. Total: 13.1056 s/iter. ETA=0:01:57\n",
      "\u001b[32m[09/30 11:49:39 d2.evaluation.evaluator]: \u001b[0mInference done 2/10. Dataloading: 2.9395 s/iter. Inference: 7.5566 s/iter. Eval: 0.0005 s/iter. Total: 10.4978 s/iter. ETA=0:01:23\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/dataset_mapper.py\", line 154, in __call__\n    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/detection_utils.py\", line 180, in read_image\n    with PathManager.open(file_name, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/iopath/common/file_io.py\", line 1012, in open\n    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/iopath/common/file_io.py\", line 604, in _open\n    return open(  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '../src/data-coco/images/val/sub-rat3_sample-data9.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m COCOEvaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../src/data-coco/annotations/json_annotation_val.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m build_detection_test_loader(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../src/data-coco/annotations/json_annotation_val.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/detectron2/evaluation/evaluator.py:155\u001b[0m, in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator, callbacks)\u001b[0m\n\u001b[1;32m    153\u001b[0m start_data_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mget(callbacks \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n\u001b[0;32m--> 155\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_data_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperf_counter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_data_time\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_warmup\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/common.py\", line 125, in __getitem__\n    data = self._map_func(self._dataset[cur_idx])\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/dataset_mapper.py\", line 154, in __call__\n    image = utils.read_image(dataset_dict[\"file_name\"], format=self.image_format)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/Desktop/mainn/A2024/NeuroPoly/NeuroPolyProjects/axon-detection/notebooks/detectron2/detectron2/data/detection_utils.py\", line 180, in read_image\n    with PathManager.open(file_name, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/iopath/common/file_io.py\", line 1012, in open\n    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/muriellemardenli/opt/anaconda3/envs/axon-detection_venv/lib/python3.12/site-packages/iopath/common/file_io.py\", line 604, in _open\n    return open(  # type: ignore\n           ^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '../src/data-coco/images/val/sub-rat3_sample-data9.png'\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"../src/data-coco/annotations/json_annotation_val.json\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"../src/data-coco/annotations/json_annotation_val.json\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79213670c13b8b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
