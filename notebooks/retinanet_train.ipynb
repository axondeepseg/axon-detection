{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82541) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (5.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "fatal: destination path 'detectron2' already exists and is not an empty directory.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82544) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82545) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (10.4.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (2.0.8)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.8 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (0.1.8)\r\n",
      "Requirement already satisfied: tabulate in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: cloudpickle in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (3.0.0)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (4.66.4)\r\n",
      "Requirement already satisfied: tensorboard in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (2.17.0)\r\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (0.1.5.post20221221)\r\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (0.1.9)\r\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: hydra-core>=1.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (1.3.2)\r\n",
      "Requirement already satisfied: black in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (24.8.0)\r\n",
      "Requirement already satisfied: packaging in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (24.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (1.26.4)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: PyYAML in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from yacs>=0.1.8) (5.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (2.1.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (1.65.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (3.6)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (4.25.4)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (70.3.0)\r\n",
      "Requirement already satisfied: six>1.9 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from tensorboard) (3.0.3)\r\n",
      "Requirement already satisfied: portalocker in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from iopath<0.1.10,>=0.1.7) (2.10.1)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from omegaconf<2.4,>=2.1) (4.9.3)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from black) (8.1.7)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from black) (1.0.0)\r\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from black) (0.12.1)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from black) (4.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/redar/PycharmProjects/summer24/axon-detection/venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# # Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:02.801451Z",
     "start_time": "2024-08-12T00:32:00.316826Z"
    }
   },
   "id": "4ef0b158b0588392",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\r\n",
      "torch:  2.3 ; cuda:  2.3.1\n",
      "detectron2: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82546) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:07.268702Z",
     "start_time": "2024-08-12T00:32:07.124644Z"
    }
   },
   "id": "ec0411de6a0ad138",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:11.424884Z",
     "start_time": "2024-08-12T00:32:11.419802Z"
    }
   },
   "id": "6462041cf4997a67",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"../src/coco/annotations/json_annotation_train.json\", {}, \"../src/coco/annotations/json_annotation_train.json\", \"../src/coco/images/train\")\n",
    "register_coco_instances(\"../src/coco/annotations/json_annotation_val.json\", {},\"../src/coco/annotations/json_annotation_val.json\" , \"../src/coco/images/val\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T00:32:12.975415Z",
     "start_time": "2024-08-12T00:32:12.970866Z"
    }
   },
   "id": "d48db80f6643ba6a",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config /Users/redar/PycharmProjects/summer24/axon-detection/notebooks/detectron2/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 20:32:15 d2.engine.defaults]: \u001B[0mModel:\n",
      "RetinaNet(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelP6P7(\n",
      "      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    )\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): RetinaNetHead(\n",
      "    (cls_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (bbox_subnet): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): ReLU()\n",
      "    )\n",
      "    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (anchor_generator): DefaultAnchorGenerator(\n",
      "    (cell_anchors): BufferList()\n",
      "  )\n",
      ")\n",
      "\u001B[32m[08/11 20:32:15 d2.data.datasets.coco]: \u001B[0mLoaded 7 images in COCO format from ../src/coco/annotations/json_annotation_train.json\n",
      "\u001B[32m[08/11 20:32:15 d2.data.build]: \u001B[0mRemoved 0 images with no usable annotations. 7 images left.\n",
      "\u001B[32m[08/11 20:32:15 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[08/11 20:32:15 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[08/11 20:32:15 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[08/11 20:32:15 d2.data.common]: \u001B[0mSerializing 7 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[08/11 20:32:15 d2.data.common]: \u001B[0mSerialized dataset takes 0.21 MiB\n",
      "\u001B[32m[08/11 20:32:15 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=2\n",
      "\u001B[32m[08/11 20:32:15 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...\n",
      "[Checkpointer] Loading from /Users/redar/.torch/iopath_cache/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/190397829/model_final_5bd44e.pkl ...\n",
      "Reading a file from 'Detectron2 Model Zoo'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001B[35mpixel_mean\u001B[0m\n",
      "  \u001B[35mpixel_std\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 20:32:15 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82557) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82558) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 20:34:09 d2.utils.events]: \u001B[0m eta: 0:24:54  iter: 19  total_loss: 3.63  loss_cls: 2.658  loss_box_reg: 1.212    time: 5.4457  last_time: 4.2307  data_time: 0.0970  last_data_time: 0.0009   lr: 1.6068e-05  \n",
      "\u001B[32m[08/11 20:36:11 d2.utils.events]: \u001B[0m eta: 0:21:42  iter: 39  total_loss: 1.69  loss_cls: 0.9278  loss_box_reg: 0.7337    time: 5.7876  last_time: 4.4728  data_time: 0.0022  last_data_time: 0.0011   lr: 3.2718e-05  \n",
      "\u001B[32m[08/11 20:38:08 d2.utils.events]: \u001B[0m eta: 0:20:02  iter: 59  total_loss: 1.074  loss_cls: 0.5188  loss_box_reg: 0.598    time: 5.8084  last_time: 4.7580  data_time: 0.0016  last_data_time: 0.0007   lr: 4.9367e-05  \n",
      "\u001B[32m[08/11 20:40:18 d2.utils.events]: \u001B[0m eta: 0:18:50  iter: 79  total_loss: 0.9819  loss_cls: 0.3456  loss_box_reg: 0.6288    time: 5.9745  last_time: 7.1580  data_time: 0.0016  last_data_time: 0.0010   lr: 6.6017e-05  \n",
      "\u001B[32m[08/11 20:42:09 d2.utils.events]: \u001B[0m eta: 0:16:47  iter: 99  total_loss: 0.8609  loss_cls: 0.2944  loss_box_reg: 0.5691    time: 5.8910  last_time: 4.6868  data_time: 0.0014  last_data_time: 0.0013   lr: 8.2668e-05  \n",
      "\u001B[32m[08/11 20:44:05 d2.utils.events]: \u001B[0m eta: 0:14:54  iter: 119  total_loss: 0.8336  loss_cls: 0.2744  loss_box_reg: 0.5672    time: 5.8806  last_time: 7.1687  data_time: 0.0016  last_data_time: 0.0007   lr: 9.9318e-05  \n",
      "\u001B[32m[08/11 20:46:19 d2.utils.events]: \u001B[0m eta: 0:13:37  iter: 139  total_loss: 0.7927  loss_cls: 0.2635  loss_box_reg: 0.5421    time: 5.9970  last_time: 10.4514  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00011597  \n",
      "\u001B[32m[08/11 20:48:19 d2.utils.events]: \u001B[0m eta: 0:12:02  iter: 159  total_loss: 0.8524  loss_cls: 0.2516  loss_box_reg: 0.597    time: 5.9964  last_time: 8.4745  data_time: 0.0014  last_data_time: 0.0002   lr: 0.00013262  \n",
      "\u001B[32m[08/11 20:50:10 d2.utils.events]: \u001B[0m eta: 0:10:19  iter: 179  total_loss: 0.7788  loss_cls: 0.2473  loss_box_reg: 0.5441    time: 5.9435  last_time: 7.3905  data_time: 0.0014  last_data_time: 0.0006   lr: 0.00014927  \n",
      "\u001B[32m[08/11 20:52:02 d2.utils.events]: \u001B[0m eta: 0:08:29  iter: 199  total_loss: 0.7575  loss_cls: 0.2328  loss_box_reg: 0.5267    time: 5.9107  last_time: 4.9138  data_time: 0.0014  last_data_time: 0.0023   lr: 0.00016592  \n",
      "\u001B[32m[08/11 20:54:12 d2.utils.events]: \u001B[0m eta: 0:06:54  iter: 219  total_loss: 0.7959  loss_cls: 0.2383  loss_box_reg: 0.5505    time: 5.9643  last_time: 5.6936  data_time: 0.0020  last_data_time: 0.0014   lr: 0.00018257  \n",
      "\u001B[32m[08/11 20:56:16 d2.utils.events]: \u001B[0m eta: 0:05:13  iter: 239  total_loss: 0.7934  loss_cls: 0.2447  loss_box_reg: 0.5601    time: 5.9847  last_time: 8.8031  data_time: 0.0020  last_data_time: 0.0008   lr: 0.00019922  \n",
      "\u001B[32m[08/11 20:58:21 d2.utils.events]: \u001B[0m eta: 0:03:29  iter: 259  total_loss: 0.8378  loss_cls: 0.2488  loss_box_reg: 0.5941    time: 6.0072  last_time: 8.2838  data_time: 0.0018  last_data_time: 0.0021   lr: 0.00021587  \n",
      "\u001B[32m[08/11 21:00:11 d2.utils.events]: \u001B[0m eta: 0:01:43  iter: 279  total_loss: 0.7691  loss_cls: 0.2251  loss_box_reg: 0.5437    time: 5.9678  last_time: 4.5405  data_time: 0.0014  last_data_time: 0.0007   lr: 0.00023252  \n",
      "Saving checkpoint to ./output/model_final.pth\n",
      "\u001B[32m[08/11 21:02:04 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 299  total_loss: 0.7671  loss_cls: 0.2262  loss_box_reg: 0.535    time: 5.9452  last_time: 7.7629  data_time: 0.0013  last_data_time: 0.0018   lr: 0.00024917  \n",
      "\u001B[32m[08/11 21:02:04 d2.engine.hooks]: \u001B[0mOverall training speed: 298 iterations in 0:29:31 (5.9452 s / it)\n",
      "\u001B[32m[08/11 21:02:04 d2.engine.hooks]: \u001B[0mTotal training time: 0:29:32 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"../src/coco/annotations/json_annotation_train.json\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.MODEL.DEVICE = \"cpu\"  # Force CPU usage\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T01:02:04.434132Z",
     "start_time": "2024-08-12T00:32:14.923334Z"
    }
   },
   "id": "f41885edc891aafe",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(83384) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T01:08:34.842564Z",
     "start_time": "2024-08-12T01:08:33.208372Z"
    }
   },
   "id": "ae2bbdde6d41682b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 21:11:32 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n",
      "[Checkpointer] Loading from ./output/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T01:11:33.216787Z",
     "start_time": "2024-08-12T01:11:32.382927Z"
    }
   },
   "id": "d6d8978d3b1fe0da",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 21:11:51 d2.evaluation.coco_evaluation]: \u001B[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001B[32m[08/11 21:11:51 d2.data.datasets.coco]: \u001B[0mLoaded 2 images in COCO format from ../src/coco/annotations/json_annotation_val.json\n",
      "\u001B[32m[08/11 21:11:51 d2.data.build]: \u001B[0mDistribution of instances among all 2 categories:\n",
      "\u001B[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|    axon    | 3146         |   myelin   | 1578         |\n",
      "|            |              |            |              |\n",
      "|   total    | 4724         |            |              |\u001B[0m\n",
      "\u001B[32m[08/11 21:11:51 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001B[32m[08/11 21:11:51 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[08/11 21:11:51 d2.data.common]: \u001B[0mSerializing 2 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[08/11 21:11:51 d2.data.common]: \u001B[0mSerialized dataset takes 0.14 MiB\n",
      "\u001B[32m[08/11 21:11:51 d2.evaluation.evaluator]: \u001B[0mStart inference on 2 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(83425) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(83426) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[08/11 21:11:55 d2.evaluation.evaluator]: \u001B[0mTotal inference time: 0:00:00.740754 (0.740754 s / iter per device, on 1 devices)\n",
      "\u001B[32m[08/11 21:11:55 d2.evaluation.evaluator]: \u001B[0mTotal inference pure compute time: 0:00:00 (0.498793 s / iter per device, on 1 devices)\n",
      "\u001B[32m[08/11 21:11:55 d2.evaluation.coco_evaluation]: \u001B[0mPreparing results for COCO format ...\n",
      "\u001B[32m[08/11 21:11:55 d2.evaluation.coco_evaluation]: \u001B[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001B[32m[08/11 21:11:55 d2.evaluation.coco_evaluation]: \u001B[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      "\u001B[32m[08/11 21:11:56 d2.evaluation.coco_evaluation]: \u001B[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.766 | 3.157  | 1.775  | 1.961 | 2.848 | 0.522 |\n",
      "\u001B[32m[08/11 21:11:56 d2.evaluation.coco_evaluation]: \u001B[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|\n",
      "| axon       | 0.806 | myelin     | 2.726 |\n",
      "OrderedDict({'bbox': {'AP': 1.7663575813152088, 'AP50': 3.157193882780996, 'AP75': 1.774986841133524, 'APs': 1.9606442476064623, 'APm': 2.847521798873057, 'APl': 0.5217060167555218, 'AP-axon': 0.8062234794908061, 'AP-myelin': 2.7264916831396113}})\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"../src/coco/annotations/json_annotation_val.json\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"../src/coco/annotations/json_annotation_val.json\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-12T01:11:56.305582Z",
     "start_time": "2024-08-12T01:11:51.732606Z"
    }
   },
   "id": "a8facc1245996c67",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d79213670c13b8b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
